{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais Convolucionais em Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# Install Tensorflow from the website: https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagens/pic1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagens/Stochastic_Gradient_Descent.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vai criar 32 feature detectors de tamanho 3x3 \n",
    "formato de input 64x64 em um 3d array RGB\n",
    "OBS -  Cuidado com os pixels negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maxpooling de 2x2  - tamanho padrão para uma boa eficiência \n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o valor de output da dimensão é por volta de 100 nodos...escolhe 128 por ser uma potência da 2...é um valor estimado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor de saída da função sigmoid é a probabilidade de ser de uma classe ou de outra...por isso que presica somente de 1 neurônio de saíad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagens/pic2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pré processamento da imagem (Direto do KERAS.com)\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mantar a escala de bits...1 para 255\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#dados de treino\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#dados de teste \n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 476s 2s/step - loss: 0.6555 - acc: 0.6130 - val_loss: 0.5863 - val_acc: 0.6902\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 414s 2s/step - loss: 0.5891 - acc: 0.6871 - val_loss: 0.5775 - val_acc: 0.7090\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 374s 1s/step - loss: 0.5686 - acc: 0.6975 - val_loss: 0.5414 - val_acc: 0.7266\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 377s 2s/step - loss: 0.5354 - acc: 0.7289 - val_loss: 0.5826 - val_acc: 0.6904\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 414s 2s/step - loss: 0.5254 - acc: 0.7350 - val_loss: 0.5369 - val_acc: 0.7322\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 426s 2s/step - loss: 0.5056 - acc: 0.7465 - val_loss: 0.5371 - val_acc: 0.7470\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 381s 2s/step - loss: 0.4862 - acc: 0.7630 - val_loss: 0.5056 - val_acc: 0.7585\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 326s 1s/step - loss: 0.4864 - acc: 0.7605 - val_loss: 0.5305 - val_acc: 0.7470\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 326s 1s/step - loss: 0.4678 - acc: 0.7732 - val_loss: 0.4985 - val_acc: 0.7705\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 359s 1s/step - loss: 0.4568 - acc: 0.7765 - val_loss: 0.5043 - val_acc: 0.7707\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 333s 1s/step - loss: 0.4444 - acc: 0.7951 - val_loss: 0.5122 - val_acc: 0.7583\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 278s 1s/step - loss: 0.4368 - acc: 0.7937 - val_loss: 0.5129 - val_acc: 0.7814\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 276s 1s/step - loss: 0.4217 - acc: 0.8039 - val_loss: 0.5201 - val_acc: 0.7526\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.4114 - acc: 0.8082 - val_loss: 0.5632 - val_acc: 0.7526\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 275s 1s/step - loss: 0.4000 - acc: 0.8140 - val_loss: 0.5346 - val_acc: 0.7528\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3913 - acc: 0.8240 - val_loss: 0.5254 - val_acc: 0.7669\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3795 - acc: 0.8250 - val_loss: 0.5210 - val_acc: 0.7601\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 1050s 4s/step - loss: 0.3680 - acc: 0.8396 - val_loss: 0.5653 - val_acc: 0.7770\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 350s 1s/step - loss: 0.3578 - acc: 0.8401 - val_loss: 0.5865 - val_acc: 0.7665\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 278s 1s/step - loss: 0.3530 - acc: 0.8427 - val_loss: 0.5273 - val_acc: 0.7796\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 356s 1s/step - loss: 0.3461 - acc: 0.8473 - val_loss: 0.5871 - val_acc: 0.7466\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 278s 1s/step - loss: 0.3290 - acc: 0.8541 - val_loss: 0.5844 - val_acc: 0.7736\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 273s 1s/step - loss: 0.3259 - acc: 0.8568 - val_loss: 0.5956 - val_acc: 0.7568\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 273s 1s/step - loss: 0.3256 - acc: 0.8584 - val_loss: 0.5575 - val_acc: 0.7751\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3200 - acc: 0.8581 - val_loss: 0.5914 - val_acc: 0.7669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10af6c898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classificador em si ....demora um pouco....\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Acurácia final foi de 85% no treino e e de 76% no teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhorar a acurácia ele sugere criar uma nova camada intermediária "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/arnaldojr/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 1052s 4s/step - loss: 0.6891 - acc: 0.5569 - val_loss: 0.6224 - val_acc: 0.6604\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 386s 2s/step - loss: 0.6019 - acc: 0.6711 - val_loss: 0.5978 - val_acc: 0.6732\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 708s 3s/step - loss: 0.5552 - acc: 0.7149 - val_loss: 0.5489 - val_acc: 0.7169\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 1021s 4s/step - loss: 0.5260 - acc: 0.7345 - val_loss: 0.5454 - val_acc: 0.7225\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 1054s 4s/step - loss: 0.5052 - acc: 0.7524 - val_loss: 0.5441 - val_acc: 0.7200\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 560s 2s/step - loss: 0.4946 - acc: 0.7540 - val_loss: 0.5207 - val_acc: 0.7478\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 1011s 4s/step - loss: 0.4795 - acc: 0.7742 - val_loss: 0.4907 - val_acc: 0.7594\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 1207s 5s/step - loss: 0.4654 - acc: 0.7809 - val_loss: 0.4723 - val_acc: 0.7742\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 1054s 4s/step - loss: 0.4448 - acc: 0.7908 - val_loss: 0.5113 - val_acc: 0.7589\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 1004s 4s/step - loss: 0.4376 - acc: 0.7954 - val_loss: 0.4834 - val_acc: 0.7781\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 636s 3s/step - loss: 0.4257 - acc: 0.8001 - val_loss: 0.4746 - val_acc: 0.7773\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 366s 1s/step - loss: 0.4124 - acc: 0.8069 - val_loss: 0.4680 - val_acc: 0.7874\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 298s 1s/step - loss: 0.4022 - acc: 0.8125 - val_loss: 0.5025 - val_acc: 0.7800\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.3947 - acc: 0.8219 - val_loss: 0.4720 - val_acc: 0.7898\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 296s 1s/step - loss: 0.3768 - acc: 0.8279 - val_loss: 0.4643 - val_acc: 0.7926\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.3690 - acc: 0.8311 - val_loss: 0.4939 - val_acc: 0.7866\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 289s 1s/step - loss: 0.3445 - acc: 0.8476 - val_loss: 0.5276 - val_acc: 0.7908\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.3400 - acc: 0.8505 - val_loss: 0.4774 - val_acc: 0.8025\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 291s 1s/step - loss: 0.3338 - acc: 0.8540 - val_loss: 0.4677 - val_acc: 0.8000\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 293s 1s/step - loss: 0.3236 - acc: 0.8543 - val_loss: 0.4669 - val_acc: 0.7995\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 293s 1s/step - loss: 0.3136 - acc: 0.8618 - val_loss: 0.4928 - val_acc: 0.7967\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.2916 - acc: 0.8767 - val_loss: 0.5144 - val_acc: 0.8116\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 293s 1s/step - loss: 0.2894 - acc: 0.8745 - val_loss: 0.5595 - val_acc: 0.7913\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.2750 - acc: 0.8793 - val_loss: 0.5978 - val_acc: 0.7888\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.2713 - acc: 0.8830 - val_loss: 0.5807 - val_acc: 0.7696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818c532b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# Install Tensorflow from the website: https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#NOVA CAMADA INTERMEDIARIA \n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Acurácia de 88% para o treino e de 77% para o teste \n",
    "\n",
    "obs: nao melhorou tanto quanto o esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OBS  ** Boas bibliotecas para o R **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/h2oai/deepwater "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/h2oai/h2o-3/tree/master/examples/deeplearning/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
